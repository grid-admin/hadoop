% Summary of main conclusions
The results presented in this paper serve as an initial evaluation of the performance of Apache Hadoop running on the EGI federated cloud infrastructure. They show that FedCloud is especially suitable for small and medium-size Hadoop jobs where the data set is already pre-deployed in the Hadoop HDFS filesystem. Considering the two use cases selected, we see that the federated cluster is even able to outperform the local one if the remote nodes are faster than the ones available locally.


% Suitability
This results show that small VM instances are good enough to run Hadoop workloads assuming an appropriate tuning of the configuration is done, of course using larger instances would simplify the configuration and it would allow to reach larger problems. In our benchmarks the \emph{tasktrackers} run out of memory when running the Wikipedia's use case if we used a small number of reduce tasks, additionally when using a small \emph{dfs.block.size} it was the \emph{jobtracker} the service that run out of memory because it was not able to cope with the large amount of tasks.

% Step 1: cluster setup
%% Scalability: Issues when starting more than 20 VMs, some fail
% Startup conclusions: startup time and reliability
The initial results showed very disappointing results about the startup times and reliability of the system. Almost 3 hours were needed to start the larger cluster with 101 nodes, a high penalty for small and medium size jobs that usually finish in less than an hour. Additionally, failures started to appear when trying to start more than 20 VMs. After analyzing in detail the startup process we saw these failures could be mainly attributed to limitations in the resource provider cloud management backend. We were able to appropriately tune both the cloud provider backend and our marketplace image, reducing the startup time to less than 20 minutes for the 101-node cluster. This optimization also lead to an improvement of the reliability of the startup process, so no more instances failed during the cluster startup process.

The startup times were compared with those of Amazon EC2. In order to run the measurements, a custom tool had to be developed for deployment of cluster larger than 20 nodes because of the request rate limit imposed by Amazon that causes Whirr to fail in such scenarios. Our measurements showed startup times of around 5 minutes for the larger 101-node cluster, but there were reliability issues in Amazon's infrastructure that caused several nodes not to work properly.

%Step 2: bechmarks


% deploying data set is very slow
There is also a large overhead introduced by the upload--\emph{put} times--of the data sets to the HDFS filesystem. In the medium-size use case it takes 10 times more to upload the data set than to run the actual job. This aspect should be taken into account when considering Hadoop on demand services.

%TeraGen/TeraSort
% rack awareness: gateway
Considering the scalability of the system we were able to run the TeraGen benchmark up to 2TB and the TeraSort benchmark up to 500GB. Even if larger targets could be reached increasing the size of the system, we found networking issues when trying to add additional instances running at additional sites. These issues seemed site-specific.

% Fedcloud improvements
%% Marketplace: the image is not automatically sync to all sites
There are some aspects that cloud improve the usability of FedCloud like adding a central workload management system, an automated way to distribute and synchronize the image between all FedCloud sites, or a mechanism to query the resources available at a given site.
%Even if we understand that sites want to have strict control over which images run in their sites, a compromise should be established between 
%% Multi-site: Lack of automatic scheduling
%% Only two sites had working rOCCI API druing the period of the benchmarks
%There is also a lack of a workload management system to automatically distribute the VM instances between the available sites. A more strict testing of the sites would also help because at the time of running the benchmarks only two sites had operational rOCCI interfaces.
%% Unable to know how many VMs we can run in a given site through occi, we can just check if they are machines pending. You have to ask the administrator of the site. It can be that there are no computing resources or that they do not have enough public IPs.
%% Limitations in the concurrent number of VMs available due to the number of available public IPs that a given site has
%A mechanism to query the resources available at a given site would be also useful.
%% firewall between sites closing hadoop port access
%Another aspect to improve is related to network access between the nodes, the global firewalls of the sites can impede certain communications and then hinder the deployment of the Hadoop service.


% Future work
%About the future work, we will study the possibility of setting up a Hadoop on demand service on top of the FedCloud infrastructure. We have already implemented such a service locally at CESGA based on our OpenNebula private cloud. Such a service would allow FedCloud other users to easily obtain a testing environment for their Hadoop jobs.

% Include the master image in the marketplace of EGI (reference the other paper)
%The set of tools created to deploy and execute the Hadoop service and the configuration files used have been uploaded to github~\cite{scripts}\cite{hadoopondemand} so they can be used by anyone interested in running Hadoop in FedCloud. 


